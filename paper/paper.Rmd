---
title: "Expectations bias moral evaluations"
author: "Derek Powell and Zachary Horne"
output: 
  pdf_document:
    keep_tex: TRUE
bibliography: library.bib
csl: apa6.csl
fontsize: 12pt
header-includes:
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead{}
    - \fancyhead[LO,LE]{PREPRINT DRAFT - PLEASE DO NOT CITE WITHOUT PERMISSION}
    - \fancyfoot[CO,CE]{}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load data, include=FALSE}
# analysis

library(tidyverse)

d_raw <- read.csv("../data/WIW+Judgment+Task+Preregistered_March+30%2C+2018_11.17.csv")

d_wide <- d_raw %>%
  rename(duration = Duration..in.seconds.) %>%
  select(workerId, age, sex, attn, duration, contains("_trial"), -contains("_trial_")) %>%
  filter(Check_trial == 0, attn == 1) %>%
  rename(
    Corruption_trial = corruption_trial,
    Clerk_trial = clerk_trial,
    Flattire_trial = flattire_trial,
    Rape_trial = rape_trial) %>%
  mutate(sex = if_else(sex == 1, "male", "female"))

reverse_items <- c( # sadly, only 6 of 10 items were reversed! :(
  "Cancer_trial",
  "Heater_trial",
  "Flattire_trial",
  "Clerk_trial",
  "Corruption_trial",
  "Rape_trial"
)

d_tidy <- d_wide %>%
  gather(trial, response, Earthquake_trial:BigDiff5_trial) %>%
  mutate(trial_type = ifelse(grepl("[0-9]", trial), "filler", "experimental")) %>%
  mutate(trial_type = ifelse(grepl("BigDiff",trial), "filler-diff", trial_type)) %>%
  mutate(likely_2nd = ifelse((trial %in% reverse_items), 1, 0))

d <- d_tidy %>%
  filter(trial_type == "experimental", trial != "Check_trial") %>%
  mutate(response = ifelse(likely_2nd==1, (1-response), response))

d2_raw <- read.csv("../data/WIW+Judgment+Task+Preregistered+-+Likert_April+20%2C+2018_17.08.csv")

d2_wide <- d2_raw %>%
  rename(duration = Duration..in.seconds.) %>%
  select(workerId, age, sex, attn, duration, contains("_trial"), -contains("_trial_")) %>%
  filter(
    Check1_trial == -1, 
    Check2_trial == -2, 
    Check3_trial == 1, 
    attn == 1,
    !is.na(workerId)
    ) %>%
  rename(
    Corruption_trial = corruption_trial,
    Clerk_trial = clerk_trial,
    Flattire_trial = flattire_trial,
    Rape_trial = rape_trial) %>%
  mutate(sex = if_else(sex == 1, "male", "female"))

# normal = more likely is 1
# reverse = less likely is 1

reverse_items2 <- c(
  "Cancer_trial",
  "Heater_trial",
  "Flattire_trial",
  "Clerk_trial",
  "Corruption_trial",
  "Rape_trial",
  "Earthquake_trial",
  "Fastfood_trial",
  "Police_trial"
)

d2_tidy <- d2_wide %>%
  select(-Check1_trial, -Check2_trial, -Check3_trial) %>%
  gather(trial, response, Tornado_trial:BigDiff5_trial) %>%
  mutate(trial_type = ifelse(grepl("[0-9]", trial), "filler", "experimental")) %>%
  mutate(trial_type = ifelse(grepl("BigDiff",trial), "filler-diff", trial_type)) %>%
  mutate(likely_2nd = ifelse((trial %in% reverse_items2), 1, 0))

d2 <- d2_tidy %>%
  filter(trial_type == "experimental") %>%
  mutate(response = ifelse(likely_2nd==1, response*-1, response))
```

```{r compute descriptives, include=FALSE}
gender_exp1 <- d %>% 
  group_by(workerId) %>% 
  summarize(sex=first(sex)) %>% 
  ungroup() %>% 
  count(sex) %>% 
  spread(sex, n)

gender_exp2 <- d2 %>% 
  group_by(workerId) %>% 
  summarize(sex=first(sex)) %>% 
  ungroup() %>% 
  count(sex) %>% 
  spread(sex, n)

age_exp1 <- d %>% 
  group_by(workerId) %>% 
  summarize(age=first(age)) %>% 
  ungroup() %>% 
  summarize(age = median(age)) %>% 
  .$age

age_exp2 <- d2 %>% 
  group_by(workerId) %>% 
  summarize(age=first(age)) %>% 
  ungroup() %>% 
  summarize(age = median(age)) %>% 
  .$age
```

```{r fit brms models, include=FALSE}
library(brms)
devtools::source_gist(id = "f1994c0f8325abbc5d300600744af39d", filename="cbrm.R")

fit_exp1 <- cbrm(
  response ~ 0 + intercept + trial + (1|workerId), # another model adds likely_2nd
  data = d,
  family = bernoulli(),
  prior = prior(normal(0,3), class="b"),
  control = list(adapt_delta = .80),
  cores = parallel::detectCores(),
  iter = 2000,
  cached_file = "fit_exp1.rds"
  )

fit_exp2 <- cbrm(
  response ~ trial + (1|workerId), # another model adds likely_2nd
  data = d2 %>% mutate(response = response + 3),
  family = cumulative(),
  prior = prior(normal(0,3), class="Intercept"),
  control = list(adapt_delta = .80),
  cores = parallel::detectCores(),
  sample_prior = TRUE,
  iter = 2000,
  cached_file = "fit_exp2.rds"
  )
```

```{r hypothesis tests, include=FALSE}
print_bf <- function(hypothesis) {
  
  bf <- hypothesis$hypothesis$Evid.Ratio
  
  if (is.na(bf)) {
    return("< .001")
  }
  else if (bf < .001) {
    return("< .001")
  }
  else if (bf > 1000) {
    return("> 1000")
  }
  else {
    return(paste("=", as.character(bf)))
  }
}

coefs_exp1 <- broom::tidy(fit_exp1) %>%
  filter(term=="b_intercept")

# coefs_exp2 <- broom::tidy(fit_exp2) %>%
#   filter(term=="b_intercept")

bf_exp1 <- hypothesis(fit_exp1, "intercept = 0")
# bf_exp1 <- h1$hypothesis$Evid.Ratio

bf_exp2 <- hypothesis(fit_exp2, "Intercept[2] = -Intercept[3]")
# bf_exp2 <- h2$hypothesis$Evid.Ratio
```

```{r make figures, include=FALSE}
fig1 <- plot(marginal_effects(fit_exp1, "trial"))
fig2 <- plot(marginal_effects(fit_exp2, "trial"))
```

# Introduction

When we learn of tragic events--a friend's loss of a loved-one, a violent killing, or a terrorist attack--we are mournful, concerned, angry, and driven to action. But our responses to these events differ depending on the context. In particular, it often seems as if our expectations, how surprising or unsurprising the event, play an important role. This seems true of both the mundane--When a friend's loved-one passes, we often ask, "was it sudden?"-- the dramatic--a murder in a sleepy town prompts a very different reaction than a similar crime in a major city--and even the catastrophic: acts of terrorism seem to evoke more outrage, horror, and concern when they occurs in peaceful rather than unstable regions. For instance, the 2015 Paris attacks were felt around the world. Yet, most of those mourning had little to say 15 hours earlier, when another tragic attack killed at least 43 people in Beirut (citation). Likewise, stories of the Virginia Tech massacre, which killed 32 people, wildly overshadowed coverage of attacks killing nearly 200 people in Iraq--one of the bloodiest days since the 2003 invasion (cite). In each of these situations, the surprise elicited by an event appears to affect evaluations. In some contexts, harm is tragic and in others, “these things happen.” 

Although this pattern seems so intuitive as to be obvious, there is no code of ethics that would justify this pattern of judgment, nor is there any moral psychological framework that can clearly explain it. (i think we could cite that kurt gray thing saying that weirdness is part of the response to purity violations). Outside of the domain of morality, however, a parallel set of everyday experiences and laboratory work shows that people’s evaluations of events unambiguously depend on their expectations about those events. There is disappointment when events fail to meet expectations, and there is a special thrill to having one’s expectations exceeded: we root for the underdog, hold surprise parties, and foreshadow bad news to ease its delivery [@Bell1985]. Indeed, laboratory work suggests that expectations play an important role in people’s evaluations of the utility of an event. For instance, Mellers and colleagues [-@Mellers1997] found that expectations influenced affective reactions during a gambling task: Given a gamble with a 10% chance to win \$30 and 90% chance to win \$0, participants felt little disappointment with the \$0 outcome, but were considerably more excited when they won \$30. Conversely, given a gamble with a 90% chance of winning \$60 and 10% chance of winning \$0, participants were disappointed with the \$0 outcome and showed more muted enjoyment of the \$60 outcome. In fact, in gambles similar to these, Mellers and colleagues [-@Mellers1997] found that people were happier with the smaller unexpected gain than with the larger but more expected gain [also see @Shepperd2002].

Expectations seem to affect people's reactions to personal gains and losses, but can these findings be extended to the types of moral situations we have highlighted thus far? That is, do expectations directly affect reactions to morally consequential events, as intuition and anecdote seem to suggest? And if so, why should expectations inform these reactions, and what does this say about the dependability of human moral judgments?

A number of researchers have sought to develop theories of disappointment--the psychological reactions that result when experiences fail to meet expectations--and its role in evaluation and decision-making [e.g., @Bell1985; @Gul1991; @Loomes1986]. These researchers have generally argued that expectations modify people's reactions to events, so that they are jointly determined by the context-free utilities of options or events (e.g., economic utilities), and the contextually-dependent disappointment that individuals experience as a function of their expectations. Similarly, Mellers and colleagues (1997) interpreted the divergence they observed between the utility of an outcome (i.e., monetary gains or losses) and the felt experience of that outcome as a result of post-decision affect. 

Each of these theories has been rigorously defined and supported within the small-world confines they were meant to capture. However, we seek to craft a more general explanation of how and why expectations influence evaluations and the range of contexts in which they should be expected to do so. Several accounts of utility evaluation, including early theories like Prospect Theory [@Kahneman1979; @Tversky1992], have emphasized the role of relative comparisons in evaluations of utility. In a similar spirit, we argue that expectations can set the reference points against which people compare future outcomes. On this view, evaluating the utility of some event consists in comparing the state of the world now that the event has occurred to the state of the world just prior to the event. Further, we assume that our knowledge of the world is uncertain, so that it is really just our (probabilistic) expectations about what has happened, what is happening, and what will happen in the future. Thus, the evaluation of an event might be driven by what is learned about the state of the world as a result of that event’s occurrence. 

The account outlined above provides an information-theoretic route to understanding how expectations directly influence evaluation. A fundamental insight of Information Theory is that the information carried by an event is a function of its prior probability. This means that low probability events carry more information than high probability events [@Shannon1948]. Along similar lines, violations of expectations have long been recognized as fundamental to associative and animal learning models; a larger delta means people learn more [e.g., @Rescorla1972]. Science progresses most when new findings impugn widely-accepted theories or when a theory’s extreme predictions are validated. Likewise, people learn more about the state of the world when their expectations are violated by shocking world events as compared to when they are affirmed by less surprising events. For example, if a bombing occurs in Paris -- an unexpected location -- rather than Lebanon --a more expected location--we learn that the world is more dangerous than we had previously believed.

A more formal treatment of these issues reveals the generality of these conclusions. Formally, before some binary event $x_i$ (which either occurs or does not occur), an evaluator has a mental model of the current state of affairs, S. This mental model includes expectations about potential future events and uncertainty over current and past events. Thus S represents a joint probability distribution over possible states of affairs $p(x_1, x_2, ..., x_n)$. The evaluator's subjective utility function can assign an expected utility to S--representing how positive or negatively the evaluator views the current state of affairs. The occurrence of $x_i$ brings about some new state of affairs, S', to which the evaluator can again apply her utility function. The evaluation of event  $x_i$ then consists in the comparison between these two states of affairs, those before the event (reflecting the agents' expectations), and the new state of affairs brought about by the event:

$$ V(x_i) = EU(S') -EU(S) $$

We let S be represented by a random vector X, whose members are any number of discrete events $x_1, x_2, ..., x_n$, where $x_i$ represents the event of interest so that $x_i$ occurs in S with some probability and occurs in S' with probability 1. That is, S represents $X$ and S' represents $X|x_i=1$. We write this as:

$$
\begin{aligned}
V(x_i) &= EU(X|x_i) - EU(X) \\
&= \sum_{x \in X} U(x)p(x|x_i) - \sum_{x \in X} U(x)p(x)
\end{aligned}$$

Applying the chain rule of probability and some algebra (see appendix) we eventually obtain:

$$V(x_i) = \big(1 - p(x_i) \big) \sum_{x \in X} U(x)p(x|x_i)$$

Thus, the value assigned to event $x_i$ is proportional to the prior probability of $x_i$. Further, this holds true regardless of the nature of the event in question and of the form of the utility function over events.

In the context of our reaction to surprise parties, it might seem desirable that expectations would influence our experience of events.  Much joy is tied to the psychological marriage between surprise and evaluation. Indeed, it seems that for information reasons alone, attending to events that tell us the most seems like an efficient way to navigate the world. 

However, the basic cognitive process we have just discussed may have negative moral repercussions. When harms are expected, these dynamics may lead people to draw less extreme evaluations, feel less concern for victims, and be less driven to help. To test this hypothesis, we examined whether people’s evaluations of morally harmful events are affected by their expectations about those events. The information-theoretic account we have sketched makes only directional predictions--predicting that, all else equal, more surprising events will elicit stronger responses than less surprising events. Thus, we examined the effects of expectations in a comparison task, where we asked people to compare pairs of simple events where a victim suffered an identical harm, but where the events differed in their prior probability. For each pair of events, participants were asked to judge which event was more upsetting. Two studies provided evidence for the predicted effect of expectations on moral evaluations: people tended to view unexpected negative events as more upsetting, even when the harm to victims was identical.

# General Methods

Here we present two preregistered studies examining the role of expectations in moral evaluations. Study 1 used a forced-choice task to test the hypothesis that people would be more upset about moral outcomes that were unexpected than expected. In Study 2, we tested of our hypothesis using a more conservative judgment task to increase the generalizability of our results. 

## Materials

In both studies, participants were presented with a series of trials where they read brief (one sentence) descriptions of two different events and were asked to indicate which of the two events seemed more upsetting. In “experimental” trials, the two events were highly similar, but differed in their prior probabilities: one event was more expected and one more unexpected. (The perceived likelihood of a given event was confirmed in prior norming studies). These prior expectations were manipulated by changing the context in which the events occurred. For example, participants considered the following stimulus: 

* “A 30 year old man in California dies in an earthquake” [Expected]

* “A 30 year old man in Oklahoma dies in an earthquake” [Unexpected]

In each event, the harm to the victim is the same (here, death) but one event is more expected than the other, given the different likelihoods of earthquakes occurring in California versus Oklahoma.

Each study contained between 16 experimental event-pairs that spanned a variety of different events and contexts. All experimental materials for these studies are available as supplemental online materials at [OSF LINK].

Both studies included “equivalent” filler trials. In these trials, the two events differed in trivial contextual details that we did not expect would affect participants’ judgments. For example: 

* “A man in Connecticut starts a house fire.” [Equally expected]

* “A man in New Hampshire starts a house fire.” [Equally expected]

These filler trials were meant to prevent participants from becoming explicitly aware of the structure of the experimental trials. Finally, both studies included “non-equivalent” filler trials, the two events differed substantially in the degree of harm suffered by a victim, so that one event was expected to be seen as considerably more upsetting than the other. For example: 

* “An 11-year-old child sets a doll on fire” [Less severe]

* “A 12-year-old child sets a cat on fire”  [More severe]

These trials were included to allow participants a chance to use the extremes of the response scale and to reduce any task demands that might drive them to make artificially fine-grained distinctions between the severity of events.

## Exclusions

In both studies, we excluded participants who failed to incorrectly answer attention-check questions. These questions asked participants to enter a particular response to ensure that they were paying attention and reading the items as they proceeded through the study. A final question asked participants if they had paid attention and taken the study seriously, encouraging them to be honest in their replies.

## Data Analysis

We analyzed our data by performing Bayesian estimation using the probabilistic programming language Stan [@Carpenter2017]. We tested our predictions by computing Bayes Factors (i.e. BF01) on the intercept term of our regression model using the hypothesis function in the R package brms. Bayes Factors express the ratio of the probability of data under the null hypothesis to the probability of the data under an alternative hypothesis. Therefore, larger Bayes Factors indicate that the data are more likely under the null hypothesis (e.g., that the intercept is not different from zero) than the alternative hypothesis (e.g., that the intercept is different from zero), and vice versa. Bayes Factors can be influenced by prior choices (Gelman, Simpson, & Betancourt, 2017) so we also performed prior robustness checks to confirm that our conclusions were unchanged under different prior assumptions.

# Study 1

Study 1 examined the hypothesis that changes in the prior probability of an event would affect people’s evaluation of that event. 

## Participants

A total of `r n_distinct(d_raw$workerId)` participants were recruited from Amazon’s Mechanical Turk work distribution website (mTurk). Of these, `r n_distinct(d$workerId)` passed attention checks and were included in the final analyses (`r gender_exp1$male` male, `r gender_exp1$female` female, median age = `r age_exp1` years old). All participants were paid $0.60 for their participation.

## Materials and procedure

Participants judged 16 experimental event-pairs and 10 equivalent filler event-pairs. The events were described in the passive voice, and participants were asked to judge which event seemed more upsetting. For example:

* A 32 year old woman gets food poisoning after eating a hamburger at a fast food restaurant. [Expected]

* A 32 year old woman gets food poisoning after eating a hamburger at a four star restaurant. [Unexpected]

On each trial, participants were presented with the event-pair stimulus and had to judge which outcome was more upsetting in a two-alternative forced choice task. The two events were labeled “Outcome 1” and “Outcome 2” and their order was randomized. 

## Results and discussion

We predicted that people would think that events where unexpected harm occurred were more upsetting than events that entail similar harm but were comparatively more expected. As indicated in Figure 1, people judged that unexpected negative events were more upsetting than expected events. To confirm this difference formally, we fit a Bayesian logistic random effects model with participants’ responses as the dependent variable (1 = unexpected event is more upsetting; 0 = expected event is more upsetting) and random intercepts for item and subject, allowing us to generalize to items and subjects we did not test. The intercept in this model represents the log-odds of selecting the unexpected event as being more upsetting. Thus, by examining the population-level intercept, we can test whether participants were biased toward selecting the unexpected event ($\beta$ > 0), the expected event ($\beta$ < 0), or were unbiased ($\beta$ = 0). Consistent with our hypothesis, we found that people were much more likely to think that unexpected events were more upsetting than events that were expected, Intercept = `r round(coefs_exp1$estimate, 3)`, 95% CI [`r round(coefs_exp1$lower, 3)`, `r round(coefs_exp1$upper, 3)`], BF01 `r print_bf(bf_exp1)`. Bayes factors and the estimate of the intercept were similar under different prior choices.

```{r figure1, echo=FALSE, fig.cap="Marginal probability of choosing more likely response as more upsetting in Experiment 1. (DRAFT FIGURE)"}

fig1$trial +
  coord_cartesian(ylim=c(0,1)) +
  geom_hline(yintercept = .5, linetype = "dashed") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Figure 1 shows participants' responses broken-down by individual items. Participants' bias toward selecting the unexpected event as more upsetting was consistent across the 16 experimental items.

# Study 2 

In Study 1 we found that people’s judgments of events were biased by their expectations about those events. When forced to choose between two events, participants decided that unexpected events were more upsetting than expected events. In Study 2, we sought to test our hypothesis using a more conservative method: we provided participants with a more expressive response scale so that if they viewed the events under consideration as equally harmful, their responses could reflect their attitude.

## Participants

A total of `r n_distinct(d2_raw$workerId)` participants were recruited from Amazon’s Mechanical Turk work distribution website (mTurk). Of these, `r n_distinct(d$workerId)` passed attention checks and were included in the final analyses (`r gender_exp2$male` male, `r gender_exp2$female` female, median age = `r age_exp2` years old). All participants were paid $0.60 for their participation.

## Materials and procedure

Participants judged 16 experimental event-pairs. One “equivalent” filler item was changed because participants did not, in fact, view the two outcomes as equally upsetting. (Specifically, participants thought it was more upsetting to have one’s right foot amputated than their left foot) [OSF LINK].

As in Study 1, on each trial of the study, participants were presented with a pair of actions labeled “Outcome 1” and “Outcome 2” and were asked, “Which outcome seems more upsetting?” However, unlike previous studies, in Study 2 participants made their rating on a five-point scale (Outcome 1 seems more upsetting, Outcome 1 seems a little more upsetting, neither seems more upsetting than the other, Outcome 2 seems a little more upsetting, Outcome 2 seems more upsetting). 

## Results and discussion

```{r figure2, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Marginal expected response (1-5 scale) in Experiment 2. A response of 3 indicates indifference, a response below 3 indicates a bias to choose the less likely response as more upsetting. (DRAFT FIGURE)"}
fig2$trial +
  coord_cartesian(ylim=c(2.25,3.25)) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The events participants were asked to compare were, by design, highly similar. Consequently, we expected that participants' would typically indicate that neither event seemed more upsetting. Indeed, we think that this response is, by most people’s lights, the right answer. This was by far the choice participants most frequently made (see Figure 1, panel 3). However, we also observed that when participants did perceive one event was more upsetting than the other, they were biased to perceive unexpected negative events as more upsetting than more-expected negative events. 

To examine these findings formally, we performed cumulative (ordinal) regression using a Bayesian random effects model with participants’ scale responses as the dependent variable (1 to 5) and random intercepts for item and subject. This model produces four intercept coefficients, representing the cumulative log-odds of responses at each scale point or higher. For instance, the second coefficient represents the log-odds participants chose a 2 ("outcome 2 seems slightly more upsetting") or lower on the scale. Similarly, the third intercept coefficient represents the log-odds participants chose a 3 or lower on the scale. By comparing the second intercept coefficient to the inverse of the third intercept coefficient (thereby representing the log-odds *not* choosing a 3 or lower--i.e., choosing a 4 or 5), we can test whether participants were more likely to choose the expected or unexpected event as being more upsetting in cases where they did not choose the neither option. This analysis indicated that people were more likely to think that events that were unexpected were more upsetting than events that were expected, BF01 `r print_bf(bf_exp2)` (see supplemental online materials for full model results) -- when participants did exhibit a bias in their responses about which event was more upsetting, they reliably chose the unexpected event was more upsetting than the expected event. 

# Discussion

On the evening of November 13th, 2015, a terrorist attack in Paris left 130 people dead and injured over 300 more. In the aftermath, millions took to Twitter to express their shock, horror, and outrage at this tragedy under hashtags like `#parisattacks` and `#jesuisparis`. Yet, most of those mourning had little to say 15 hours earlier, when another tragic attack killed at least 43 people in Beirut. Several factors are surely at play in these different reactions  [e.g. group affiliations, @Brewer1999; construal-level theory, @Trope2010], yet one potentially fundamental factor has gone unmentioned: the fact that the Paris attack was more surprising than the attack in Beirut.  In contrast to France, Lebanon had experienced dozens of terrorist bombings and attacks in recent years. Consequently, Beirut may seem to many like the sort of place where “these things happen,” whereas Paris is perceived as being stable and safe.

Consistent with this hypothesis, the results of two preregistered studies suggest that people view unexpected harmful events as more upsetting than expected harmful events. Just as people react more strongly to unexpected monetary gains and losses [@Mellers1997], people similarly are more upset by unexpected moral harm than expected moral harm. However, unlike in the context of gambles, in these contexts the effects of expectations on evaluations may have harmful consequences. When events are shocking, people may perceive them as more severe and consequently be roused to action. In contrast, when events harm victims who are generally considered to be at greater risk--the poor, sick, or those living in unstable regions of the world, reactions are likely to be more muted. 

What is the source of this bias: prior judgment and decision-making research along with Information Theory suggests that  these effects are unlikely to be a domain-specific quirk of moral thinking and more likely to be a product of information-theoretic mechanisms. The striking consequence of this is that it is quite likely that the bias to ignore expected harm exists because it allows us to efficiently navigation of the world around us; paying attention to events that surprise us allows us to learn the most about the world. But the consequences of this bias seems unambiguously sub-optimal. 

Understood in this way, the inconsistency in people’s attitudes about otherwise similar acts of terrorism seems almost intuitive. An act of terrorism in a peaceful nation might be less expected because of our beliefs about the effectiveness of security forces, the stability of national relationships, and positive relationships among people groups in that nation. In contrast, a surprising act of terrorism casts doubt on our deeper understanding of the geopolitical situation, and thereby leads us to suspect similar acts are more likely to occur in the future. This could rightly increase our concern about this event.  

However, this bias--regardless of whether it is rooted in otherwise reasonable information-theoretic mechanisms--threatens to impose a vicious and morally pernicious cycle. For instance, people living in geo-politically unstable regions or in the developing world are often those who are most affected by terrorism, famine, and natural disasters, and are the very people in greatest need of assistance and concern from the world at-large. However, for these very reasons, it is often unsurprising when harm befalls people living in these circumstances. Stated another way, expected but nonetheless devastating events elicit little concern, and thus cause people to be less likely to donate time or money to aid victims, or to take political action. Understanding the mechanism that leads people to exhibit a bias where they will be least likely to help those in most need of attention can guide policymakers and psychologists to develop interventions which allow people to overcome this default tendency. 

The information-theoretic account has further implications, including offering a unifying explanation for related moral judgment behavior. For instance, the account we’ve discussed can elucidate why people appear to distinguish between acts of omission (e.g., failing to save someone’s life) and commission (e.g., actively killing someone). Most people feel (Spranca, Minsk, & Baron, 1991), and many ethicists argue (e.g., Foot, 1967; Kagan, 1988; Kamm, 1993; Kant 1780/1965; Thomson, 1986), that immoral acts of commission may seem like more severe moral violations than are acts of omission that produce similar outcomes. Our account may shed light on this phenomena: when a person is in a position to be harmed through another’s inaction, that person tends to be at greater risk of harm than a person who can only be harmed through direct action. Therefore, omission generally leads to a smaller change in moral utility than do acts of commission, potentially explaining its less severe moral implications. 

To consider one more example, our account may provide an explanation of certain types of victim blaming. Often, female victims of sexual harassment and assault are held partially responsible for the actions of their male aggressors. This is especially true if they were dressed or acting promiscuously, or if they willfully became intoxicated prior to the assault. People seemingly believe that a woman who behaves in these ways increases the probability that she will suffer sexual assault. Research by Janoff-Bullman, Timko, and Carli (1984) indicates that people are more likely to hold victims accountable for their own rape when the rape was perceived as having a greater prior probability, even when a victim’s behaviors were the same. Not only are victims sometimes held accountable for their own assaults, but victim blaming also serves to shift blame away from the aggressor, leading some people to partially or completely excuse their transgressions. Although these counter-normative attitudes are often extrinsically motivated by misogyny (cite), our account may explain some aspects of this tendency. When people perceive a victims’ actions as increasing the probability of their eventual assault, this affects their utility evaluations of an aggressor’s actions: an aggressor’s actions produce a smaller change in utility, thus warranting weaker condemnation. 

# Acknowledgements

We would like to acknowledge the help of Larisa Hussak, Keith Holyoak, Alan Fiske, Matthew Lieberman, Hongjing Lu, John Hummel, Andrei Cimpian, and Ellen Markman for their comments and support.


# Appendix

$$ \begin{aligned}
V(x_i) &= EU(X|x_i) - EU(X) \\
&=  \sum_{x \in X} U(x)p(x|x_i) - \sum_{x \in X} U(x)p(x) \\
&= \sum_{x \in X} U(x)p(x|x_i) - \sum_{x \in X} U(x)p(x|x_i)p(x_i) \\
&= \sum_{x \in X} U(x)p(x|x_i) - p(x_i)\sum_{x \in X} U(x)p(x|x_i) \\
&= \big(1 - p(x_i) \big) \sum_{x \in X} U(x)p(x|x_i) \\
\end{aligned}$$

The first step utilizes the Law of the Unconscious Statistician, the next comes from the chain rule of probability, and the final two steps are simple algebra.

# References

\setlength{\parindent}{-0.125in} 
\setlength{\leftskip}{0.125in}
\noindent