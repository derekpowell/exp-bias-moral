---
title: Expectations bias moral evaluations

# Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
author:
  - name: Derek Powell
    affiliation: a,1
  - name: Zachary Horne
    affiliation: b
address:
  - code: a
    address: Stanford University, Department of Psychology, 450 Serra Mall, Stanford, CA, 94305
  - code: b
    address: Arizona State University, School of Social and Behavioral Sciences, 13591 N 47th Ave, Phoenix, AZ 85051

corresponding_author:
  - code: 1
    text: "To whom correspondence should be addressed. E-mail: derekpowell@stanford.edu"

# For footer text
lead_author_surname: Powell

## Remove this if not required - talk to zach 
# equal_authors:
#   - code: 0
#     text: 


author_contributions: |
  Both authors jointly conceived of the project and theory, designed and conducted experiments, and analyzed results. D.P. developed the formal aspects of the theory. 

## Remove this if not required
conflict_of_interest: |
  The authors declare no conflicts of interest.

abstract: |
 When we learn of tragic events--a violent killing or a terrorist attack--we are mournful and often driven to action. But our responses to these events can differ substantially depending on the context of the event. When tragedy takes us by surprise, we are shocked and outraged, but when it strikes in unstable regions or rough neighborhoods, we are often resigned to feel that “these things happen.” Here we explain the role that expectations seem to play in moral evaluation by modeling evaluations as the comparison of the state of the world before and after an event. According to this model, expectations influence evaluations through information-theoretic principles: less expected events do more to inform us about the state of the world than do more expected events. Consistent with this theory, in two preregistered studies we found that people’s judgments of morally significant events were affected by the prior probability of that event, so that people were more upset about an event that was unexpected (e.g., a robbery at a clothing store) than an event that was more more probable (e.g., a robbery at a convenience store). This bias threatens to impose a pernicious cycle: People living in poverty, geo-politically unstable regions, and other dangerous circumstances have the greatest need for assistance and concern. However, for these very reasons, it is often unsurprising when they are harmed. Consequently, the influence of expectations on moral evaluations threatens to reduce observer's concern for those people who are most in need.



significance: |
  In two behavioral studies, we found that people's expectations biased their reactions to morally-significant events--people are more upset by surprising harms than more expected harms. This bias appears deeply pernicious: because it is often unsurprising when people living in poverty, dangerous neighborhoods, or unstable regions become victims of crime, natural disasters, or terrorism, observers are likely to experience reduced concern for these victims. Yet people living in disadvantaged circumstances are those most in need of assistance and concern from the world at-large. By blunting people's concern for those victims who are most in need, the bias we have uncovered threatens to increase their suffering and further sustain inequality.



acknowledgements: |
  We would like to acknowledge the help of Larisa Hussak, Keith Holyoak, Alan Fiske, Hongjing Lu, John Hummel, Andrei Cimpian, and Ellen Markman for their comments and support.

keywords:
  - evaluation
  - moral judgment
  - information theory
  # - optional
  # - optional

## must be one of: pnasresearcharticle (usual two-column layout), pnasmathematics (one column layout), or pnasinvited (invited submissions only)
pnas_type: pnasresearcharticle

bibliography: wiw-biblio.bib
csl: pnas.csl

## change to true to add optional line numbering
lineno: FALSE

output: rticles::pnas_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load data, include=FALSE}
# analysis

library(tidyverse)

d_raw <- read.csv("../data/WIW+Judgment+Task+Preregistered_March+30%2C+2018_11.17.csv")

d_wide <- d_raw %>%
  filter(DistributionChannel=="anonymous") %>%
  rename(duration = Duration..in.seconds.) %>%
  select(workerId, age, sex, attn, duration, contains("_trial"), -contains("_trial_")) %>%
  filter(Check_trial == 0, attn == 1) %>%
  rename(
    Corruption_trial = corruption_trial,
    Clerk_trial = clerk_trial,
    Flattire_trial = flattire_trial,
    Rape_trial = rape_trial) %>%
  mutate(sex = if_else(sex == 1, "male", "female"))

reverse_items <- c( # sadly, only 6 of 10 items were reversed! :(
  "Cancer_trial",
  "Heater_trial",
  "Flattire_trial",
  "Clerk_trial",
  "Corruption_trial",
  "Rape_trial"
)

d_tidy <- d_wide %>%
  gather(trial, response, Earthquake_trial:BigDiff5_trial) %>%
  mutate(trial_type = ifelse(grepl("[0-9]", trial), "filler", "experimental")) %>%
  mutate(trial_type = ifelse(grepl("BigDiff",trial), "filler-diff", trial_type)) %>%
  mutate(likely_2nd = ifelse((trial %in% reverse_items), 1, 0))

d <- d_tidy %>%
  filter(trial_type == "experimental", trial != "Check_trial") %>%
  mutate(response = ifelse(likely_2nd==1, (1-response), response)) %>%
  mutate(response = abs(response-1)) %>%
  mutate(trial = gsub("_trial","",trial))

d2_raw <- read.csv("../data/WIW+Judgment+Task+Preregistered+-+Likert_April+20%2C+2018_17.08.csv")

d2_wide <- d2_raw %>%
  filter(DistributionChannel=="anonymous") %>%
  rename(duration = Duration..in.seconds.) %>%
  select(workerId, age, sex, attn, duration, contains("_trial"), -contains("_trial_")) %>%
  filter(
    Check1_trial == -1, 
    Check2_trial == -2, 
    Check3_trial == 1, 
    attn == 1,
    !is.na(workerId)
    ) %>%
  rename(
    Corruption_trial = corruption_trial,
    Clerk_trial = clerk_trial,
    Flattire_trial = flattire_trial,
    Rape_trial = rape_trial) %>%
  mutate(sex = if_else(sex == 1, "male", "female"))

# normal = more likely is 1
# reverse = less likely is 1

reverse_items2 <- c(
  "Cancer_trial",
  "Heater_trial",
  "Flattire_trial",
  "Clerk_trial",
  "Corruption_trial",
  "Rape_trial",
  "Earthquake_trial",
  "Fastfood_trial",
  "Police_trial"
)

d2_tidy <- d2_wide %>%
  select(-Check1_trial, -Check2_trial, -Check3_trial) %>%
  gather(trial, response, Tornado_trial:BigDiff5_trial) %>%
  mutate(trial_type = ifelse(grepl("[0-9]", trial), "filler", "experimental")) %>%
  mutate(trial_type = ifelse(grepl("BigDiff",trial), "filler-diff", trial_type)) %>%
  mutate(likely_2nd = ifelse((trial %in% reverse_items2), 1, 0))

d2 <- d2_tidy %>%
  filter(trial_type == "experimental") %>%
  mutate(response = ifelse(likely_2nd==1, response*-1, response)) %>%
  mutate(response = -1*response) %>%
  mutate(response = response + 3) %>%
  mutate(trial = gsub("_trial","",trial))
```

```{r compute descriptives, include=FALSE}
gender_exp1 <- d %>% 
  group_by(workerId) %>% 
  summarize(sex=first(sex)) %>% 
  ungroup() %>% 
  count(sex) %>% 
  spread(sex, n)

gender_exp2 <- d2 %>% 
  group_by(workerId) %>% 
  summarize(sex=first(sex)) %>% 
  ungroup() %>% 
  count(sex) %>% 
  spread(sex, n)

age_exp1 <- d %>% 
  group_by(workerId) %>% 
  summarize(age=first(age)) %>% 
  ungroup() %>% 
  summarize(age = median(age)) %>% 
  .$age

age_exp2 <- d2 %>% 
  group_by(workerId) %>% 
  summarize(age=first(age)) %>% 
  ungroup() %>% 
  summarize(age = median(age)) %>% 
  .$age
```

```{r fit brms models, include=FALSE}
library(brms)
devtools::source_gist(id = "f1994c0f8325abbc5d300600744af39d", filename="cbrm.R")

fit_exp1 <- cbrm(
  response ~ 0 + intercept + trial + (1|workerId), # another model adds likely_2nd
  data = d,
  family = bernoulli(),
  prior = prior(normal(0,3), class="b"),
  control = list(adapt_delta = .80),
  cores = parallel::detectCores(),
  sample_prior = TRUE,
  iter = 2000,
  cached_file = "fit_exp1.rds"
  )

fit_exp2 <- cbrm(
  response ~ trial + (1|workerId), # another model adds likely_2nd
  data = d2,
  family = cumulative(),
  prior = prior(normal(0,3), class="Intercept"),
  control = list(adapt_delta = .80),
  cores = parallel::detectCores(),
  sample_prior = TRUE,
  iter = 2000,
  cached_file = "fit_exp2.rds"
  )

fit_exp1rand <- cbrm(
  response ~ 0 + intercept + (1|trial) + (1|workerId), # another model adds likely_2nd
  data = d,
  family = bernoulli(),
  prior = prior(normal(0,3), class="b"),
  control = list(adapt_delta = .80),
  sample_prior = TRUE,
  cores = parallel::detectCores(),
  iter = 2000,
  cached_file = "fit_exp1rand.rds"
  )

fit_exp2rand <- cbrm(
  response ~ (1|trial) + (1|workerId), # another model adds likely_2nd
  data = d2,
  family = cumulative(),
  prior = prior(normal(0,3), class="Intercept"),
  control = list(adapt_delta = .80),
  cores = parallel::detectCores(),
  sample_prior = TRUE,
  iter = 2000,
  cached_file = "fit_exp2rand.rds"
  )
```

```{r hypothesis tests, include=FALSE}
print_bf <- function(hypothesis) {
  
  bf <- hypothesis$hypothesis$Evid.Ratio
  
  if (is.na(bf)) {
    return("< .001")
  }
  else if (bf < .001) {
    return("< .001")
  }
  else if (bf > 1000) {
    return("> 1000")
  }
  else {
    return(paste("=", as.character(bf)))
  }
}

coefs_exp1 <- broom::tidy(fit_exp1rand) %>%
  filter(term=="b_intercept")

# coefs_exp2 <- broom::tidy(fit_exp2) %>%
#   filter(term=="b_intercept")

bf_exp1 <- hypothesis(fit_exp1rand, "intercept = 0")
# bf_exp1 <- h1$hypothesis$Evid.Ratio

bf_exp2 <- hypothesis(fit_exp2rand, "-Intercept[2] = Intercept[3]")
# bf_exp2 <- h2$hypothesis$Evid.Ratio
```

```{r make figures, include=FALSE}
fig1 <- plot(marginal_effects(fit_exp1, "trial"))
fig_exp1 <- fig1$trial$data %>%
  ggplot() +
  aes(x = reorder(trial, -estimate__), y = estimate__, ymin = lower__, ymax = upper__) +
  geom_errorbar(width=.25) +
  geom_point(shape=17, size = 2) +
  coord_cartesian(ylim=c(0,1)) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "grey") +
  theme_bw() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    aspect.ratio = .75,
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = .7)
    ) +
  labs(
    x = "Trial",
    y = "Probability of judging less\nexpected more upsetting"
  ) 
# library(gridExtra)
# grid.arrange(ggplotGrob(fig_exp1))

ggsave("fig1.eps",fig_exp1, height=8.7, width=8.7, unit="cm")
```

```{r fig2, include=FALSE}

fig2_cont <- marginal_effects(fit_exp2, "trial", plot=FALSE)
fig2 <- plot(marginal_effects(fit_exp2, "trial", ordinal=TRUE))

plt_cont <- fig2_cont$trial %>%
  ggplot() +
  aes(x = reorder(trial, -estimate__), y = estimate__, ymin = lower__, ymax = upper__) +
  geom_errorbar(width=0) +
  geom_point(shape=17, size = 1) +
  coord_cartesian(ylim=c(2,4)) +
  geom_hline(yintercept = 3, linetype = "dashed", color = "grey") +
  theme_bw() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    aspect.ratio = 10/16,
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = .7)
  ) +
  labs(
    x = "Trial",
    y = '"Upsetting" Judgments'
  ) 

plt_heatmap <- fig2$trial$data %>%
  left_join(
    fig2_cont$trial %>% 
              rename(mean_estimate = estimate__) %>%
              select(trial, mean_estimate)
            , by = "trial"
    ) %>%
  ggplot(aes(y = cats__, x = reorder(trial, -mean_estimate), fill = estimate__)) +
  geom_tile(color="white") + 
  scale_fill_viridis_c(
    option="B", 
    limits=c(0,1), 
    breaks = c(0, .25, .5, .75, 1), 
    labels= c(0, .25, .5, .75, 1),
    guide = guide_colorbar(
      title.position="top", 
      barheight = unit(.5, "cm")
      )
    ) +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    # aspect.ratio = 1,
    legend.position = "top",
    legend.key.width = unit(.75,"cm"),
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = .7)
  ) +
  labs(
    x = "Trial",
    y = "Response",
    fill = "Probability"
  ) +
  coord_fixed(ratio=1)

library(gtable)
g2 <- ggplotGrob(plt_cont + theme(
  axis.title.y = element_text(margin = margin(t=0,b=.5,l=0,r=.25,unit="cm")) # this is a kludge to get shared axis
))
g3 <- ggplotGrob(plt_heatmap + theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  axis.text.x = element_blank()
  ))

g <- rbind(g3, g2, size = "last")
# grid.arrange(g)

library(gridExtra)

ggsave("fig2.eps", grid.arrange(g), height=11.4, width=8.7, units = "cm")
```

When we learn of tragic events--a friend's loss of a loved-one, a violent killing, or a terrorist attack--we are mournful, concerned, angry, and driven to action. But our responses to these events differ depending on the context in which these events occur [e.g., @Trope2010]. In particular, our expectations play an important role in our reactions to events. This seems true of both the mundane--when a friend's loved-one passes, we often ask, "was it sudden?"--the dramatic--a murder in a sleepy town prompts a very different reaction than a similar crime in a major city--and even the catastrophic: acts of terrorism seem to evoke more outrage, horror, and concern when they occurs in peaceful rather than unstable regions. For instance, the 2015 Paris attacks were felt around the world. Yet, most of those mourning had little to say 15 hours earlier, when another tragic attack killed at least 43 people in Beirut [@Graham2015]. Likewise, stories of the Virginia Tech massacre, which killed 32 people, wildly overshadowed coverage of attacks killing nearly 200 people in Iraq--one of the bloodiest days since the 2003 invasion [@Greenslade2007]. In each of these situations, the surprise elicited by an event appears to affect people’s reactions to the event. In some contexts, harm is tragic and in others, “these things happen.” 

Although this pattern seems so intuitive as to be obvious, no reasonable code of ethics would justify this pattern of judgment, nor do any moral psychological frameworks explicate the role of expectations in moral evaluations. Outside of the domain of morality, everyday experiences and controlled experiments show that people’s evaluations of events unambiguously depend on their expectations about those events. There is a special thrill to having one’s expectations exceeded and disappointment when events fail to meet expectations: we root for the underdog, hold surprise parties, and foreshadow bad news to ease its delivery [@Bell1985]. Indeed, in a controlled study, Mellers and colleagues [-@Mellers1997] found that expectations influenced affective reactions during a gambling task: Given a gamble with a 10% chance to win \$30 and 90% chance to win \$0, participants felt little disappointment with the \$0 outcome, but were considerably more excited when they won \$30. Conversely, given a gamble with a 90% chance of winning \$60 and 10% chance of winning \$0, participants were disappointed with the \$0 outcome and showed more muted enjoyment of the \$60 outcome. In fact, in gambles similar to these, people were happier with the smaller unexpected gain than with the larger but more expected gain [also see @Shepperd2002]. 

The influence of expectations on moral evaluations threatens to produce negative social consequences. Tragedies are tragic, whether expected or not, and failure to recognize that could lead to tacit endorsement of the pain and suffering of others wherever pain and suffering are the status quo. Do expectations directly bias reactions to morally consequential events, as intuition and anecdote seem to suggest? To demonstrate the plausibility of this suggestion, we develop a theoretical account of how expectations influence evaluations, not as a strange quirk or uniquely human bias, but instead as a fundamental component of how people evaluate events. 

Most events of consequence consist of changes--a transition from one state to another. For this reason, we construe event evaluation as a comparison between the states of the world before and after the event. Comparison plays a crucial role in many theories of decision-making, and especially in theories aimed at explaining the role of expectations in evaluation  [e.g., @Bell1985; @Gul1991; @Loomes1986; @Mellers1997]. For instance, in Prospect Theory [@Kahneman1979; @Tversky1992], the utility of a prospect is evaluated by comparison to a current reference point. Our proposal is similar: we argue that expectations can set the reference points against which people compare future outcomes, so that assigning value to an event consists in comparing the state of the world following the event to the state of the world just prior to the event. We further assume that people’s knowledge of the world is uncertain, so we represent the states of the world probabilistically. This means that a person’s model for the state of the world is just their expectations about what has happened, what is happening, and what will happen in the future. One direct implication of this proposal is that the evaluation of an event is linked to what is learned about the world as a result of that event’s occurrence. That is, we evaluate events positively or negatively to the extent that they inform our understanding of the world in positive or negative ways.

One striking implication of this account is that it provides an information-theoretic route to understanding how expectations directly influence evaluation. A fundamental insight of Information Theory is that the information carried by an event is a function of its prior probability; low probability events carry more information than high probability events [@Shannon1948]. We propose that people learn more about the state of the world when their expectations are violated by shocking world events as compared to when they are affirmed by less surprising events. For example, if a bombing occurs in Paris--a less expected location--rather than Lebanon--a more expected location--we learn that the world is more dangerous than we had previously believed. This suggestion is novel in the moral domain, but these points are widely accepted elsewhere. For instance, expectations have long been recognized as fundamental to models of human and animal learning [e.g., @Rescorla1972].

A more formal treatment of this theory establishes the potential for its generality across domains. Let the state of the world prior to some event be represented by a random variable, $X$. We'll assume $X$ is discrete, and that every realization $x$ represents some potential specific state of the world in all relevant aspects under consideration. An agent has some utility function $u$, that applies over the different realizations of $X$. Thus the expected utility of the present state of the world is:

\begin{equation*}
E_X[u(X)] = \sum_x u(x)p(x)
\end{equation*}

When we learn an event has occurred, we can represent this as an observation of a second, binary random variable, $S$. We can think of $S$ as a "signalling event" that informs us about about $X$ [following the formalism deployed by @Arrow1996]. That is, we assume there is a dependency between $S$ and $X$, so that observing $S$ informs us about the state of the world, $X$. For instance, reading a news report of a terror attack in Brussels informs us about the state of the world, telling us about what realizations of $X$ are no longer possible (e.g., any wherein it was a peaceful day in Brussels) and which are more or less likely. Conditioned on $S$, the expected utility of the world is:

\begin{equation*}
E_{X|S}[u(X)] = \sum_x u(x)p(x|s)
\end{equation*}

Our construal of event evaluation is as a comparison between states of the world following and prior to an event. Consequently, we define the value assigned to the signalling event, $V(S)$, as:

\begin{equation*}
V(S) = E_{X|S}[u(X)] - E_X[u(X)]
\end{equation*}

From this it can be shown that the value assigned to event $S$ is proportional to its prior probability (see Theoretical Formalization). Specifically, it is the difference in the expected utility under different values of $S$, weighted by the inverse of the prior probability of $S$.. [^1]

\begin{equation*}
V(s=1)=(1-p(s=1))\sum_x u(x)p(x|s=1) - u(x)p(x|s=0)
\end{equation*}

This conclusion does not depend on the nature of the event in question nor on the utility function over events, but instead holds generally wherever we conceive of evaluation as a holistic comparison between uncertain states of the world. Consequently, this account predicts expectations will equally affect reactions to gambles with clearly specified values and probabilities [@Mellers1997] and real-world events with ill-defined values and where reasoners' expectations are defined by their existing beliefs and world knowledge. 

Given the potentially fundamental role expectations play in event evaluation, and the potentially serious moral biases that may result, we sought to test empirically whether people’s evaluations of morally harmful events are affected by their expectations about those events. We conducted two preregistered studies examining the role of expectations in moral evaluations. In both studies, participants were presented with a series of trials where they read brief descriptions of two different events and were asked to indicate which of the two events seemed more upsetting. In these trials, the two events were highly similar, but were manipulated so that they differed in their perceived prior probabilities: one event was more expected and one more unexpected. 

The design of these studies was chosen with special consideration to two theoretical points. First, the information-theoretic account we have described makes a solely directional prediction--all else being equal, more surprising events will elicit stronger reactions than less surprising events. Asking participants to compare two similar events allowed us to test this directional prediction. Second, it is the informativeness of events, determined by one's prior expectations of the event, that we predict will shape evaluations. Thus, reasoners should not have to be induced to hold expectations experimentally [as in experiments by @Mellers1997], but instead their own prior beliefs will be sufficient to shape their expectations and affect their evaluations. For this reason, we manipulated the prior probability of events by describing two otherwise identical events occurring in different contexts. We explicitly chose contexts that differed in ways that could not be accounted for by construal-level explanations (@Trope2010) or explanations based on biases towards one’s ingroup (@Brewer1979). This allowed us to test the role of expectations based on world knowledge, as well as providing a more naturalistic set of items.

![Probability with which participants chose the less expected event as more upsetting across trials in Study 1. As predicted, participants exhibited a robust bias toward choosing the less expected event as more upsetting across all items. Error bars represent 95% credible intervals calculated from the hierarchical logistic regression model. See Supporting Information for full description of items. <span data-label="fig:fig1"></span>](fig1.eps)

Consistent with our predictions, manipulating expectations consistently shaped evaluations across a range of morally-significant events. We found that people viewed unexpected harmful events as more upsetting than expected harmful events, even when the harm a victim suffered was the same. For instance, people judged that a robbery at a clothing store (unexpected) was more upsetting than a robbery at a convenience store (expected). Furthermore, these differences were large, systematic, and robust. Although there was variability in the situations that elicited the largest differences, our statistical approach treated trial as a random effect (see Methods and Results), allowing us to generalize our conclusions to items we did not test [@Judd2012].

![Participants’ responses by item in Study 2. Upper: heatmap plot displaying probability of choosing each response on the 1 to 5 scale across items. Lower: marginal expected response across items, with 95% credible interval calculated from the ordinal regression model. Note the scale has been constrained to show relevant region of results. In both plots, response of 3 indicates indifference, a response below 3 indicates a bias to choose the more expected event as more upsetting, and a response above 3 indicates a bias to choose the less expected event as more upsetting. Similar to Study 1, when participants judged that one of the events was more upsetting, they showed a robust bias toward choosing the less expected event as more upsetting. Trials are sorted by response to aid readability. <span data-label="fig:fig1"></span>](fig2.eps)

We have argued that expectations shape our reactions to events because they determine how informative those events are in shaping our understanding of the world. Thus, we argue that well-grounded information theoretic principles can account for people’s divergent moral reactions to likely and unlikely events. 

There's a sense in which it is clearly adaptive that the violation of our expectations would direct our attention to the events and situations about which our understanding is most in need of revision. For instance, an act of terrorism in a peaceful nation might be less expected because of our beliefs about the effectiveness of security forces, the stability of national relationships, and positive relationships among people groups in that nation. Therefore, a surprising act of terrorism casts doubt on our deeper understanding of the geopolitical situation, and thereby leads us to suspect similar acts are more likely to occur in the future. 

Yet, however well-grounded the underlying principles, there’s a clear moral danger whenever expectations influence our moral concerns [@Koss2000; -@Janoff-bulman1985]. These effects pose a significant threat when considering our reactions to humanitarian challenges brought on by poverty or regional instability. In these cases, the influence of expectations on moral evaluations threatens to impose vicious and morally pernicious cycles. For instance, people living in geo-politically unstable regions or in the developing world are often those who are most affected by terrorism, famine, and natural disasters, and are the very people in greatest need of assistance and concern from the world at-large. However, for these very reasons, it is often unsurprising when harm befalls people living in these circumstances. Thus the influence of expectations on moral evaluations threatens to reduce observer's concern for these victims most in need, making people less likely to donate time or money to aid victims, or to take political action to prevent further harms. The present research identifies this potentially pernicious moral bias and grounds it in information theoretic principles. Hopefully, by further understanding these cognitive dynamics, psychologists and policymakers can begin to find ways to reduce or counteract people's tendency to ignore the plight of those in most need of attention.

# Materials and Methods {#materials-and-methods .unnumbered}

We conducted two preregistered studies examining the role of expectations in moral evaluations (https://osf.io/86rsw/). Each study consisted of multiple trials where participants were presented brief descriptions of two events. Their task was to decide which of the two events was more upsetting. In Study 1, they made a two-alternative forced-choice, and in Study 2 they made their judgments using a five-point rating scale.  Both studies consisted of 16 experimental trials, five “equivalent” filler trials, and five “non-equivalent” filler trials.

In experimental trials, the two events described identical harms, but one event was more expected and one more unexpected, as determined in a prior norming study (see SI).  For example, participants considered the following stimulus: 

* “A 30 year old man in California dies in an earthquake” [Expected]

* “A 30 year old man in Oklahoma dies in an earthquake” [Unexpected]

In each of these events, the harm to the victim is the same (death) but one event is more probable than the other, given the different likelihoods of earthquakes occurring in California versus Oklahoma. In addition to being more naturalistic, manipulating expectations through (otherwise irrelevant) contextual details helps ensure that the harm suffered by the victim is understood to be identical. In the context of gambles, it is possible to manipulate probabilities specifically and directly [@Mellers1997]. However, in the context of more realistic moral harms, any attempt to directly manipulate probabilities risks also changing participants’ perceptions of the degree of harm. For instance, suppose we describe two cancer patients, one with a 5% chance of survival and one with a 50% chance of survival. Even if they both ultimately meet the same fate, participants might fairly assume the patient with the lower chance of survival had a more serious illness, was more debilitated, suffered more severely, and so forth. In contrast, changing the context of the two events explains away these likelihood differences, better equating the events in other respects.

Both studies also included “equivalent” filler trials. In these trials, the two events differed in trivial contextual details that we did not expect would affect participants’ judgments. These filler trials were meant to prevent participants from becoming explicitly aware of the structure of the experimental trials. Finally, both studies included “non-equivalent” filler trials, the two events differed substantially in the degree of harm suffered by a victim, so that one event was expected to be seen as considerably more upsetting than the other. These trials were included to allow participants a chance to use the extremes of the response scale and to reduce any task demands that might drive them to make artificially fine-grained distinctions when generating their responses. All experimental materials for these studies are available as Supporting Information at https://osf.io/86rsw/.

## Exclusions {#exclusions .unnumbered}

In both studies, we excluded participants who failed to correctly answer attention-check questions or who indicated at the end of the study they had not taken their participation seriously. 

## Data Analysis {#data-analysis .unnumbered}

We analyzed our data by performing Bayesian estimation using the probabilistic programming language Stan [@Carpenter2017]. We tested our preregistered predictions by computing Bayes Factors (i.e. BF01) using the hypothesis function in the R package brms. Bayes Factors express the ratio of the probability of data under the null hypothesis to the probability of the data under an alternative hypothesis. Larger Bayes Factors indicate that the data are more likely under the null hypothesis (i.e., that the intercept is not different from zero) than the alternative hypothesis (i.e., that the intercept is different from zero), and vice versa. As Bayes Factors can be influenced by prior choices (Gelman, Simpson, & Betancourt, 2017), we performed prior robustness checks to confirm that our conclusions would not depend substantially on the specification of the priors. 

To ensure the generality of our findings, we tested participants’ reactions to a variety of items and treated both participants and items as random effects throughout our analyses. The use of random effects over items allows us to consider these items as a sample from a larger population of possible items, and to generalize our findings to that wider population, much as we generalize from our sample of participants to the larger population [@Judd2012].

## Study 1 {#study1 .unnumbered}

### Participants {#s1-participants .unnumbered}

A total of `r n_distinct(d_raw$workerId)` participants were recruited from Amazon’s Mechanical Turk work distribution website (mTurk). Of these, `r n_distinct(d$workerId)` passed attention checks and were included in the final analyses (`r gender_exp1$male` male, `r gender_exp1$female` female, median age = `r age_exp1` years old). All participants were paid $0.60 for their participation.

### Materials and procedure {#s1-materials-procedure .unnumbered}

Participants judged 16 experimental event-pairs and 10 equivalent filler event-pairs. On each trial (an example is shown above), participants were presented with the event-pair stimulus and had to judge which outcome was more upsetting in a two-alternative forced choice task. The two events were labeled “Outcome 1” and “Outcome 2” and the order, and whether Outcome 1 or 2 was the unexpected event, was randomized and counter-balanced. 

### Results and discussion {#s1-results .unnumbered}

We predicted that people would judge that events where unexpected harm occurred were more upsetting than events where expected harm occurred. As indicated in Figure 1, we observed this trend. We estimated the magnitude of this effect by fitting a Bayesian logistic random effects model with participants’ responses as the dependent variable (1 = unexpected event is more upsetting; 0 = expected event is more upsetting) and random intercepts for item and subject, allowing us to generalize both to items and subjects we did not test. The intercept in this model represents the log-odds of selecting the unexpected event as being more upsetting. Thus, by examining the population-level intercept, we can test whether participants were biased toward selecting the unexpected event ($\beta$ > 0), the expected event ($\beta$ < 0), or were unbiased ($\beta$ = 0). We found that people were considerably more likely to think that unexpected events were more upsetting than events that were expected, Intercept = `r round(coefs_exp1$estimate, 3)`, 95% CI [`r round(coefs_exp1$lower, 3)`, `r round(coefs_exp1$upper, 3)`], BF01 `r print_bf(bf_exp1)`.
Figure 1 shows participants' responses broken-down by individual items. Participants' bias toward selecting the unexpected event as more upsetting was consistent across the 16 experimental items.

## Study 2 {#study2 .unnumbered}

In Study 1 we found that people’s judgments of events were biased by their expectations about those events. When forced to choose between two events, participants decided that unexpected events were more upsetting than expected events. In Study 2, we sought to test our hypothesis using a more conservative method: we provided participants with a more expressive response scale so that if they viewed the events under consideration as equally harmful, their responses could reflect their attitude.

### Participants {#s2-participants .unnumbered}

A total of `r n_distinct(d2_raw$workerId)` participants were recruited from Amazon’s Mechanical Turk work distribution website (mTurk). Of these, `r n_distinct(d2$workerId)` passed attention checks and were included in the final analyses (`r gender_exp2$male` male, `r gender_exp2$female` female, median age = `r age_exp2` years old). All participants were paid $0.60 for their participation.

### Materials and procedure {#s2-materials-procedure .unnumbered}

The materials in Study 2 were the same as those in Study 1. As in Study 1, on each trial of the study, participants were presented with a pair of actions labeled “Outcome 1” and “Outcome 2” and were asked, “Which outcome seems more upsetting?” In Study 2 participants made their rating on a five-point scale (Outcome 1 seems more upsetting, Outcome 1 seems a little more upsetting, neither seems more upsetting than the other, Outcome 2 seems a little more upsetting, Outcome 2 seems more upsetting). 

### Results and discussion {#s2-results .unnumbered}

We predicted that participants would evaluate unexpected events as more upsetting than expected events. We estimated the magnitude of this effect by fitting a cumulative (ordinal) random effects model with participants’ scale responses as the dependent variable (1 to 5) and random intercepts for item and subject. This model produces four intercept coefficients, representing the cumulative log-odds of responses at each scale point or lower. For instance, the second coefficient represents the log-odds participants chose a 2 ("outcome 2 seems slightly more upsetting") or lower on the scale. Similarly, the third intercept coefficient represents the log-odds participants chose a 3 or lower on the scale. To examine the predicted effect, we compared the third intercept coefficient (representing the log-odds of choosing 4 or higher) to the inverse of the second intercept coefficient (thereby representing the log-odds *not* choosing a 3 or higher--i.e., choosing a 1 or 2), allowing us to test whether participants were more likely to choose the expected or unexpected event as being more upsetting in cases where they did not choose the neither option. This analysis indicated that people were more likely to think that events that were unexpected were more upsetting than events that were expected, BF01 `r print_bf(bf_exp2)` (see supporting information for full model results). We observed this difference consistently across nearly every item (Figure 2). 

We note that the most common response was to view both events, which involve identical harms, as equivalently upsetting. However, across almost every item, participants showed a clear bias towards choosing unexpected events as more upsetting. Thus, Study 2 replicates the tendency to view unexpected moral events as more upsetting using a more conservative judgment task. 

# Theoretical Formalization {#theory .unnumbered}

Evaluation of utility is often examined in the context of decision-making. However, people often generate post hoc evaluations of events for their own sake. For instance, people evaluate events to judge the wisdom of their decisions or the morality of their actions. 

We construe event evaluation as a comparison between the state of affairs prior to an event and the state of affairs following the event. We represent the state of the world as a random variable, $X$. We assume $X$ is discrete, and that every realization $x$ represents some potential specific state of the world in all relevant aspects under consideration. An agent has some utility function $u$, that applies over the different realizations of $X$. Thus the expected utility of the present state of the world is:

\begin{equation*}
E_X[u(X)] = \sum_x u(x)p(x)
\end{equation*}

When we learn an event has occurred, we can represent this as an observation of another random variable, $S$. We can think of $S$ as a "signalling event" because it informs (signals) to us something about $X$ [this formalism follows @Arrow1996]. For simplicity, we treat $S$ as binary, either 1 or 0. Importantly, we assume there is a dependency between $S$ and $X$, so that observing $S$ informs our knowledge of $X$. For instance, reading a news report of a terror attack in Brussels informs us about the state of the world, telling us about what realizations of X are no longer possible (e.g., any wherein it was a peaceful day in Brussels) and which are more or less likely. Conditioned on $S$, the expected utility of the world is:

\begin{equation*}
E_{X|S}[u(X)] = \sum_x u(x)p(x|s)
\end{equation*}

We define the value assigned to the signalling event, $V(S)$, as:

\begin{equation}
V(S) = E_{X|S}[u(X)] - E_X[u(X)]
\end{equation}

Which we write more specifically as:

\begin{equation}
V(s=1) = \sum_x u(x)p(x|s=1) - \sum_x u(x)p(x)
\end{equation}

Our goal is to express this relation in terms of $p(S)$. First, we manipulate $E_X[u(X)]$ by applying the expectation of conditional expectation and some algebra.

\begin{align*}
\sum_x u(x)p(x) & = \sum_s u(x)p(x|s)p(s) \\
 &= \begin{aligned}[t]
    & \sum_x u(x)p(x|s=1)p(s=1) - \\
    & \quad \sum_x u(x)p(x|s=0)p(s=0) \end{aligned}\\
 &= \begin{aligned}[t]
    & p(s=1)\sum_x u(x)p(x|s=1) -\\
    & \quad p(s=0) \sum_x u(x)p(x|s=0) \end{aligned}\\
 &= \begin{aligned}[t]
    & p(s=1)\sum_x u(x)p(x|s=1) - \\
    & \quad (1-p(s=1)) \sum_x u(x)p(x|s=0) \end{aligned}\\
\end{align*}

Substituting this quantity back into Equation 2, we obtain:

\begin{align*}
V(s=1) = & \sum_x u(x)p(x|s=1) - \\ & p(s=1)\sum_x u(x)p(x|s=1) -\\ & (1-p(s=1)) \sum_x u(x)p(x|s=0)
\end{align*}

Finally, we factor the first two sums and combine them with the last sum to yield:

\begin{equation}
V(s=1)=(1-p(s=1))\sum_x u(x)p(x|s=1) - u(x)p(x|s=0)
\end{equation}

Thus, it can be seen under this formalization that the role of expectations in the evaluation of events is fundamental in the sense that it does not depend on any specifics concerning the utility function over states of the world. Instead, this conclusion depends on just two assumptions: first, that events are evaluated by comparing the utilities of the states of the world prior to and following the event; and second, that knowledge of those states of the world is uncertain.

We have appealed to the informativeness of an event to illustrate intuitively how expectations should influence evaluations. More expected events carry less information, and thereby engender weaker reactions. Though our model of event evaluation is not an information-theoretic model in a direct sense, this interpretation still applies: the information carried by observing $S$ is a function of that observation’s prior probability, which we have in turn shown determines its evaluation.

[^1]: It should be recognized that the result we obtain here bears a similarity to the “disappointment function” included in Mellers and colleagues’ [-@Mellers1997] Decision Affect Theory.


<!-- Leave these lines as they are at the end of your .Rmd file to ensure placement of methods & acknowledgements sections before the references-->
\showmatmethods
\showacknow
\pnasbreak
