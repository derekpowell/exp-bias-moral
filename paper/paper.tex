\documentclass[12pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Expectations bias moral evaluations},
            pdfauthor={Derek Powell and Zachary Horne},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Expectations bias moral evaluations}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Derek Powell and Zachary Horne}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
    \date{}
    \predate{}\postdate{}
  
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[LO,LE]{PREPRINT DRAFT - PLEASE DO NOT CITE WITHOUT PERMISSION}
\fancyfoot[CO,CE]{}

\begin{document}
\maketitle

\section{Introduction}\label{introduction}

When we learn of tragic events--a friend's loss of a loved-one, a
violent killing, or a terrorist attack--we are mournful, concerned,
angry, and driven to action. But our responses to these events differ
depending on the context. In particular, it often seems as if our
expectations, how surprising or unsurprising the event, play an
important role. This seems true of both the mundane--When a friend's
loved-one passes, we often ask, ``was it sudden?''-- the dramatic--a
murder in a sleepy town prompts a very different reaction than a similar
crime in a major city--and even the catastrophic: acts of terrorism seem
to evoke more outrage, horror, and concern when they occurs in peaceful
rather than unstable regions. For instance, the 2015 Paris attacks were
felt around the world. Yet, most of those mourning had little to say 15
hours earlier, when another tragic attack killed at least 43 people in
Beirut (citation). Likewise, stories of the Virginia Tech massacre,
which killed 32 people, wildly overshadowed coverage of attacks killing
nearly 200 people in Iraq--one of the bloodiest days since the 2003
invasion (cite). In each of these situations, the surprise elicited by
an event appears to affect evaluations. In some contexts, harm is tragic
and in others, ``these things happen.''

Although this pattern seems so intuitive as to be obvious, there is no
code of ethics that would justify this pattern of judgment, nor is there
any moral psychological framework that can clearly explain it. (i think
we could cite that kurt gray thing saying that weirdness is part of the
response to purity violations). Outside of the domain of morality,
however, a parallel set of everyday experiences and laboratory work
shows that people's evaluations of events unambiguously depend on their
expectations about those events. There is disappointment when events
fail to meet expectations, and there is a special thrill to having one's
expectations exceeded: we root for the underdog, hold surprise parties,
and foreshadow bad news to ease its delivery (Bell, 1985). Indeed,
laboratory work suggests that expectations play an important role in
people's evaluations of the utility of an event. For instance, Mellers
and colleagues (1997) found that expectations influenced affective
reactions during a gambling task: Given a gamble with a 10\% chance to
win \$30 and 90\% chance to win \$0, participants felt little
disappointment with the \$0 outcome, but were considerably more excited
when they won \$30. Conversely, given a gamble with a 90\% chance of
winning \$60 and 10\% chance of winning \$0, participants were
disappointed with the \$0 outcome and showed more muted enjoyment of the
\$60 outcome. In fact, in gambles similar to these, Mellers and
colleagues (1997) found that people were happier with the smaller
unexpected gain than with the larger but more expected gain (also see
Shepperd \& Mcnulty, 2002).

Expectations seem to affect people's reactions to personal gains and
losses, but can these findings be extended to the types of moral
situations we have highlighted thus far? That is, do expectations
directly affect reactions to morally consequential events, as intuition
and anecdote seem to suggest? And if so, why should expectations inform
these reactions, and what does this say about the dependability of human
moral judgments?

A number of researchers have sought to develop theories of
disappointment--the psychological reactions that result when experiences
fail to meet expectations--and its role in evaluation and
decision-making (e.g., Bell, 1985; Gul, 1991; Loomes \& Sugden, 1986).
These researchers have generally argued that expectations modify
people's reactions to events, so that they are jointly determined by the
context-free utilities of options or events (e.g., economic utilities),
and the contextually-dependent disappointment that individuals
experience as a function of their expectations. Similarly, Mellers and
colleagues (1997) interpreted the divergence they observed between the
utility of an outcome (i.e., monetary gains or losses) and the felt
experience of that outcome as a result of post-decision affect.

Each of these theories has been rigorously defined and supported within
the small-world confines they were meant to capture. However, we seek to
craft a more general explanation of how and why expectations influence
evaluations and the range of contexts in which they should be expected
to do so. Several accounts of utility evaluation, including early
theories like Prospect Theory (Kahneman \& Tversky, 1979; Tversky \&
Kahneman, 1992), have emphasized the role of relative comparisons in
evaluations of utility. In a similar spirit, we argue that expectations
can set the reference points against which people compare future
outcomes. On this view, evaluating the utility of some event consists in
comparing the state of the world now that the event has occurred to the
state of the world just prior to the event. Further, we assume that our
knowledge of the world is uncertain, so that it is really just our
(probabilistic) expectations about what has happened, what is happening,
and what will happen in the future. Thus, the evaluation of an event
might be driven by what is learned about the state of the world as a
result of that event's occurrence.

The account outlined above provides an information-theoretic route to
understanding how expectations directly influence evaluation. A
fundamental insight of Information Theory is that the information
carried by an event is a function of its prior probability. This means
that low probability events carry more information than high probability
events (Shannon, 1948). Along similar lines, violations of expectations
have long been recognized as fundamental to associative and animal
learning models; a larger delta means people learn more (e.g., Rescorla
\& Wagner, 1972). Science progresses most when new findings impugn
widely-accepted theories or when a theory's extreme predictions are
validated. Likewise, people learn more about the state of the world when
their expectations are violated by shocking world events as compared to
when they are affirmed by less surprising events. For example, if a
bombing occurs in Paris -- an unexpected location -- rather than Lebanon
--a more expected location--we learn that the world is more dangerous
than we had previously believed.

A more formal treatment of these issues reveals the generality of these
conclusions. Formally, before some binary event \(x_i\) (which either
occurs or does not occur), an evaluator has a mental model of the
current state of affairs, S. This mental model includes expectations
about potential future events and uncertainty over current and past
events. Thus S represents a joint probability distribution over possible
states of affairs \(p(x_1, x_2, ..., x_n)\). The evaluator's subjective
utility function can assign an expected utility to S--representing how
positive or negatively the evaluator views the current state of affairs.
The occurrence of \(x_i\) brings about some new state of affairs, S', to
which the evaluator can again apply her utility function. The evaluation
of event \(x_i\) then consists in the comparison between these two
states of affairs, those before the event (reflecting the agents'
expectations), and the new state of affairs brought about by the event:

\[ V(x_i) = EU(S') -EU(S) \]

We let S be represented by a random vector X, whose members are any
number of discrete events \(x_1, x_2, ..., x_n\), where \(x_i\)
represents the event of interest so that \(x_i\) occurs in S with some
probability and occurs in S' with probability 1. That is, S represents
\(X\) and S' represents \(X|x_i=1\). We write this as:

\[
\begin{aligned}
V(x_i) &= EU(X|x_i) - EU(X) \\
&= \sum_{x \in X} U(x)p(x|x_i) - \sum_{x \in X} U(x)p(x)
\end{aligned}\]

Applying the chain rule of probability and some algebra (see appendix)
we eventually obtain:

\[V(x_i) = \big(1 - p(x_i) \big) \sum_{x \in X} U(x)p(x|x_i)\]

Thus, the value assigned to event \(x_i\) is proportional to the prior
probability of \(x_i\). Further, this holds true regardless of the
nature of the event in question and of the form of the utility function
over events.

In the context of our reaction to surprise parties, it might seem
desirable that expectations would influence our experience of events.
Much joy is tied to the psychological marriage between surprise and
evaluation. Indeed, it seems that for information reasons alone,
attending to events that tell us the most seems like an efficient way to
navigate the world.

However, the basic cognitive process we have just discussed may have
negative moral repercussions. When harms are expected, these dynamics
may lead people to draw less extreme evaluations, feel less concern for
victims, and be less driven to help. To test this hypothesis, we
examined whether people's evaluations of morally harmful events are
affected by their expectations about those events. The
information-theoretic account we have sketched makes only directional
predictions--predicting that, all else equal, more surprising events
will elicit stronger responses than less surprising events. Thus, we
examined the effects of expectations in a comparison task, where we
asked people to compare pairs of simple events where a victim suffered
an identical harm, but where the events differed in their prior
probability. For each pair of events, participants were asked to judge
which event was more upsetting. Two studies provided evidence for the
predicted effect of expectations on moral evaluations: people tended to
view unexpected negative events as more upsetting, even when the harm to
victims was identical.

\section{General Methods}\label{general-methods}

Here we present two preregistered studies examining the role of
expectations in moral evaluations. Study 1 used a forced-choice task to
test the hypothesis that people would be more upset about moral outcomes
that were unexpected than expected. In Study 2, we tested of our
hypothesis using a more conservative judgment task to increase the
generalizability of our results.

\subsection{Materials}\label{materials}

In both studies, participants were presented with a series of trials
where they read brief (one sentence) descriptions of two different
events and were asked to indicate which of the two events seemed more
upsetting. In ``experimental'' trials, the two events were highly
similar, but differed in their prior probabilities: one event was more
expected and one more unexpected. (The perceived likelihood of a given
event was confirmed in prior norming studies). These prior expectations
were manipulated by changing the context in which the events occurred.
For example, participants considered the following stimulus:

\begin{itemize}
\item
  ``A 30 year old man in California dies in an earthquake''
  {[}Expected{]}
\item
  ``A 30 year old man in Oklahoma dies in an earthquake''
  {[}Unexpected{]}
\end{itemize}

In each event, the harm to the victim is the same (here, death) but one
event is more expected than the other, given the different likelihoods
of earthquakes occurring in California versus Oklahoma.

Each study contained between 16 experimental event-pairs that spanned a
variety of different events and contexts. All experimental materials for
these studies are available as supplemental online materials at {[}OSF
LINK{]}.

Both studies included ``equivalent'' filler trials. In these trials, the
two events differed in trivial contextual details that we did not expect
would affect participants' judgments. For example:

\begin{itemize}
\item
  ``A man in Connecticut starts a house fire.'' {[}Equally expected{]}
\item
  ``A man in New Hampshire starts a house fire.'' {[}Equally expected{]}
\end{itemize}

These filler trials were meant to prevent participants from becoming
explicitly aware of the structure of the experimental trials. Finally,
both studies included ``non-equivalent'' filler trials, the two events
differed substantially in the degree of harm suffered by a victim, so
that one event was expected to be seen as considerably more upsetting
than the other. For example:

\begin{itemize}
\item
  ``An 11-year-old child sets a doll on fire'' {[}Less severe{]}
\item
  ``A 12-year-old child sets a cat on fire'' {[}More severe{]}
\end{itemize}

These trials were included to allow participants a chance to use the
extremes of the response scale and to reduce any task demands that might
drive them to make artificially fine-grained distinctions between the
severity of events.

\subsection{Exclusions}\label{exclusions}

In both studies, we excluded participants who failed to incorrectly
answer attention-check questions. These questions asked participants to
enter a particular response to ensure that they were paying attention
and reading the items as they proceeded through the study. A final
question asked participants if they had paid attention and taken the
study seriously, encouraging them to be honest in their replies.

\subsection{Data Analysis}\label{data-analysis}

We analyzed our data by performing Bayesian estimation using the
probabilistic programming language Stan (Carpenter et al., 2017). We
tested our predictions by computing Bayes Factors (i.e.~BF01) on the
intercept term of our regression model using the hypothesis function in
the R package brms. Bayes Factors express the ratio of the probability
of data under the null hypothesis to the probability of the data under
an alternative hypothesis. Therefore, larger Bayes Factors indicate that
the data are more likely under the null hypothesis (e.g., that the
intercept is not different from zero) than the alternative hypothesis
(e.g., that the intercept is different from zero), and vice versa. Bayes
Factors can be influenced by prior choices (Gelman, Simpson, \&
Betancourt, 2017) so we also performed prior robustness checks to
confirm that our conclusions were unchanged under different prior
assumptions.

\section{Study 1}\label{study-1}

Study 1 examined the hypothesis that changes in the prior probability of
an event would affect people's evaluation of that event.

\subsection{Participants}\label{participants}

A total of 255 participants were recruited from Amazon's Mechanical Turk
work distribution website (mTurk). Of these, 230 passed attention checks
and were included in the final analyses (105 male, 125 female, median
age = 33 years old). All participants were paid \$0.60 for their
participation.

\subsection{Materials and procedure}\label{materials-and-procedure}

Participants judged 16 experimental event-pairs and 10 equivalent filler
event-pairs. The events were described in the passive voice, and
participants were asked to judge which event seemed more upsetting. For
example:

\begin{itemize}
\item
  A 32 year old woman gets food poisoning after eating a hamburger at a
  fast food restaurant. {[}Expected{]}
\item
  A 32 year old woman gets food poisoning after eating a hamburger at a
  four star restaurant. {[}Unexpected{]}
\end{itemize}

On each trial, participants were presented with the event-pair stimulus
and had to judge which outcome was more upsetting in a two-alternative
forced choice task. The two events were labeled ``Outcome 1'' and
``Outcome 2'' and their order was randomized.

\subsection{Results and discussion}\label{results-and-discussion}

We predicted that people would think that events where unexpected harm
occurred were more upsetting than events that entail similar harm but
were comparatively more expected. As indicated in Figure 1, people
judged that unexpected negative events were more upsetting than expected
events. To confirm this difference formally, we fit a Bayesian logistic
random effects model with participants' responses as the dependent
variable (1 = unexpected event is more upsetting; 0 = expected event is
more upsetting) and random intercepts for item and subject, allowing us
to generalize to items and subjects we did not test. The intercept in
this model represents the log-odds of selecting the unexpected event as
being more upsetting. Thus, by examining the population-level intercept,
we can test whether participants were biased toward selecting the
unexpected event (\(\beta\) \textgreater{} 0), the expected event
(\(\beta\) \textless{} 0), or were unbiased (\(\beta\) = 0). Consistent
with our hypothesis, we found that people were much more likely to think
that unexpected events were more upsetting than events that were
expected, Intercept = -0.647, 95\% CI {[}-0.923, -0.378{]}, BF01
\textless{} .001. Bayes factors and the estimate of the intercept were
similar under different prior choices.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/figure1-1.pdf}
\caption{Marginal probability of choosing more likely response as more
upsetting in Experiment 1. (DRAFT FIGURE)}
\end{figure}

Figure 1 shows participants' responses broken-down by individual items.
Participants' bias toward selecting the unexpected event as more
upsetting was consistent across the 16 experimental items.

\section{Study 2}\label{study-2}

In Study 1 we found that people's judgments of events were biased by
their expectations about those events. When forced to choose between two
events, participants decided that unexpected events were more upsetting
than expected events. In Study 2, we sought to test our hypothesis using
a more conservative method: we provided participants with a more
expressive response scale so that if they viewed the events under
consideration as equally harmful, their responses could reflect their
attitude.

\subsection{Participants}\label{participants-1}

A total of 504 participants were recruited from Amazon's Mechanical Turk
work distribution website (mTurk). Of these, 230 passed attention checks
and were included in the final analyses (174 male, 199 female, median
age = 34 years old). All participants were paid \$0.60 for their
participation.

\subsection{Materials and procedure}\label{materials-and-procedure-1}

Participants judged 16 experimental event-pairs. One ``equivalent''
filler item was changed because participants did not, in fact, view the
two outcomes as equally upsetting. (Specifically, participants thought
it was more upsetting to have one's right foot amputated than their left
foot) {[}OSF LINK{]}.

As in Study 1, on each trial of the study, participants were presented
with a pair of actions labeled ``Outcome 1'' and ``Outcome 2'' and were
asked, ``Which outcome seems more upsetting?'' However, unlike previous
studies, in Study 2 participants made their rating on a five-point scale
(Outcome 1 seems more upsetting, Outcome 1 seems a little more
upsetting, neither seems more upsetting than the other, Outcome 2 seems
a little more upsetting, Outcome 2 seems more upsetting).

\subsection{Results and discussion}\label{results-and-discussion-1}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/figure2-1.pdf}
\caption{Marginal expected response (1-5 scale) in Experiment 2. A
response of 3 indicates indifference, a response below 3 indicates a
bias to choose the less likely response as more upsetting. (DRAFT
FIGURE)}
\end{figure}

The events participants were asked to compare were, by design, highly
similar. Consequently, we expected that participants' would typically
indicate that neither event seemed more upsetting. Indeed, we think that
this response is, by most people's lights, the right answer. This was by
far the choice participants most frequently made (see Figure 1, panel
3). However, we also observed that when participants did perceive one
event was more upsetting than the other, they were biased to perceive
unexpected negative events as more upsetting than more-expected negative
events.

To examine these findings formally, we performed cumulative (ordinal)
regression using a Bayesian random effects model with participants'
scale responses as the dependent variable (1 to 5) and random intercepts
for item and subject. This model produces four intercept coefficients,
representing the cumulative log-odds of responses at each scale point or
higher. For instance, the second coefficient represents the log-odds
participants chose a 2 (``outcome 2 seems slightly more upsetting'') or
lower on the scale. Similarly, the third intercept coefficient
represents the log-odds participants chose a 3 or lower on the scale. By
comparing the second intercept coefficient to the inverse of the third
intercept coefficient (thereby representing the log-odds \emph{not}
choosing a 3 or lower--i.e., choosing a 4 or 5), we can test whether
participants were more likely to choose the expected or unexpected event
as being more upsetting in cases where they did not choose the neither
option. This analysis indicated that people were more likely to think
that events that were unexpected were more upsetting than events that
were expected, BF01 \textless{} .001 (see supplemental online materials
for full model results) -- when participants did exhibit a bias in their
responses about which event was more upsetting, they reliably chose the
unexpected event was more upsetting than the expected event.

\section{Discussion}\label{discussion}

On the evening of November 13th, 2015, a terrorist attack in Paris left
130 people dead and injured over 300 more. In the aftermath, millions
took to Twitter to express their shock, horror, and outrage at this
tragedy under hashtags like \texttt{\#parisattacks} and
\texttt{\#jesuisparis}. Yet, most of those mourning had little to say 15
hours earlier, when another tragic attack killed at least 43 people in
Beirut. Several factors are surely at play in these different reactions
(e.g.~group affiliations, Brewer, 1999; construal-level theory, Trope \&
Liberman, 2010), yet one potentially fundamental factor has gone
unmentioned: the fact that the Paris attack was more surprising than the
attack in Beirut. In contrast to France, Lebanon had experienced dozens
of terrorist bombings and attacks in recent years. Consequently, Beirut
may seem to many like the sort of place where ``these things happen,''
whereas Paris is perceived as being stable and safe.

Consistent with this hypothesis, the results of two preregistered
studies suggest that people view unexpected harmful events as more
upsetting than expected harmful events. Just as people react more
strongly to unexpected monetary gains and losses (Mellers et al., 1997),
people similarly are more upset by unexpected moral harm than expected
moral harm. However, unlike in the context of gambles, in these contexts
the effects of expectations on evaluations may have harmful
consequences. When events are shocking, people may perceive them as more
severe and consequently be roused to action. In contrast, when events
harm victims who are generally considered to be at greater risk--the
poor, sick, or those living in unstable regions of the world, reactions
are likely to be more muted.

What is the source of this bias: prior judgment and decision-making
research along with Information Theory suggests that these effects are
unlikely to be a domain-specific quirk of moral thinking and more likely
to be a product of information-theoretic mechanisms. The striking
consequence of this is that it is quite likely that the bias to ignore
expected harm exists because it allows us to efficiently navigation of
the world around us; paying attention to events that surprise us allows
us to learn the most about the world. But the consequences of this bias
seems unambiguously sub-optimal.

Understood in this way, the inconsistency in people's attitudes about
otherwise similar acts of terrorism seems almost intuitive. An act of
terrorism in a peaceful nation might be less expected because of our
beliefs about the effectiveness of security forces, the stability of
national relationships, and positive relationships among people groups
in that nation. In contrast, a surprising act of terrorism casts doubt
on our deeper understanding of the geopolitical situation, and thereby
leads us to suspect similar acts are more likely to occur in the future.
This could rightly increase our concern about this event.

However, this bias--regardless of whether it is rooted in otherwise
reasonable information-theoretic mechanisms--threatens to impose a
vicious and morally pernicious cycle. For instance, people living in
geo-politically unstable regions or in the developing world are often
those who are most affected by terrorism, famine, and natural disasters,
and are the very people in greatest need of assistance and concern from
the world at-large. However, for these very reasons, it is often
unsurprising when harm befalls people living in these circumstances.
Stated another way, expected but nonetheless devastating events elicit
little concern, and thus cause people to be less likely to donate time
or money to aid victims, or to take political action. Understanding the
mechanism that leads people to exhibit a bias where they will be least
likely to help those in most need of attention can guide policymakers
and psychologists to develop interventions which allow people to
overcome this default tendency.

The information-theoretic account has further implications, including
offering a unifying explanation for related moral judgment behavior. For
instance, the account we've discussed can elucidate why people appear to
distinguish between acts of omission (e.g., failing to save someone's
life) and commission (e.g., actively killing someone). Most people feel
(Spranca, Minsk, \& Baron, 1991), and many ethicists argue (e.g., Foot,
1967; Kagan, 1988; Kamm, 1993; Kant 1780/1965; Thomson, 1986), that
immoral acts of commission may seem like more severe moral violations
than are acts of omission that produce similar outcomes. Our account may
shed light on this phenomena: when a person is in a position to be
harmed through another's inaction, that person tends to be at greater
risk of harm than a person who can only be harmed through direct action.
Therefore, omission generally leads to a smaller change in moral utility
than do acts of commission, potentially explaining its less severe moral
implications.

To consider one more example, our account may provide an explanation of
certain types of victim blaming. Often, female victims of sexual
harassment and assault are held partially responsible for the actions of
their male aggressors. This is especially true if they were dressed or
acting promiscuously, or if they willfully became intoxicated prior to
the assault. People seemingly believe that a woman who behaves in these
ways increases the probability that she will suffer sexual assault.
Research by Janoff-Bullman, Timko, and Carli (1984) indicates that
people are more likely to hold victims accountable for their own rape
when the rape was perceived as having a greater prior probability, even
when a victim's behaviors were the same. Not only are victims sometimes
held accountable for their own assaults, but victim blaming also serves
to shift blame away from the aggressor, leading some people to partially
or completely excuse their transgressions. Although these
counter-normative attitudes are often extrinsically motivated by
misogyny (cite), our account may explain some aspects of this tendency.
When people perceive a victims' actions as increasing the probability of
their eventual assault, this affects their utility evaluations of an
aggressor's actions: an aggressor's actions produce a smaller change in
utility, thus warranting weaker condemnation.

\section{Acknowledgements}\label{acknowledgements}

We would like to acknowledge the help of Larisa Hussak, Keith Holyoak,
Alan Fiske, Matthew Lieberman, Hongjing Lu, John Hummel, Andrei Cimpian,
and Ellen Markman for their comments and support.

\section{Appendix}\label{appendix}

\[ \begin{aligned}
V(x_i) &= EU(X|x_i) - EU(X) \\
&=  \sum_{x \in X} U(x)p(x|x_i) - \sum_{x \in X} U(x)p(x) \\
&= \sum_{x \in X} U(x)p(x|x_i) - \sum_{x \in X} U(x)p(x|x_i)p(x_i) \\
&= \sum_{x \in X} U(x)p(x|x_i) - p(x_i)\sum_{x \in X} U(x)p(x|x_i) \\
&= \big(1 - p(x_i) \big) \sum_{x \in X} U(x)p(x|x_i) \\
\end{aligned}\]

The first step utilizes the Law of the Unconscious Statistician, the
next comes from the chain rule of probability, and the final two steps
are simple algebra.

\section{References}\label{references}

\setlength{\parindent}{-0.125in} \setlength{\leftskip}{0.125in}
\noindent

\hypertarget{refs}{}
\hypertarget{ref-Bell1985}{}
Bell, D. (1985). Disappointment In Decision Making Under Uncertainty.
\emph{Operations Research}, \emph{33}(1), 1--27.
\url{http://doi.org/10.1287/opre.33.1.1}

\hypertarget{ref-Brewer1999}{}
Brewer, M. B. (1999). The psychology of prejudice: Ingroup love or
outgroup hate? \emph{Journal of Social Issues}, \emph{55}(3), 429--444.
\url{http://doi.org/10.1111/0022-4537.00126}

\hypertarget{ref-Carpenter2017}{}
Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B.,
Betancourt, M., \ldots{} Riddell, A. (2017). Stan: A probabilistic
programming language. \emph{Journal of Statistical Software},
\emph{76}(1). \url{http://doi.org/10.18637/jss.v076.i01}

\hypertarget{ref-Gul1991}{}
Gul, F. (1991). A theory of disappointment aversion.
\emph{Econometrica}, \emph{59}(3), 667--686.
\url{http://doi.org/10.2307/2938223}

\hypertarget{ref-Kahneman1979}{}
Kahneman, D., \& Tversky, A. (1979). Prospect Theory: An Analysis of
Decision under Risk. \emph{Econometrica}, \emph{47}(2), 263--292.

\hypertarget{ref-Loomes1986}{}
Loomes, G., \& Sugden, R. (1986). Disappointment and Dynamic Consistency
in Choice under Uncertainty. \emph{Review of Economic Studies},
\emph{53}(2), 271--282. \url{http://doi.org/10.2307/2297651}

\hypertarget{ref-Mellers1997}{}
Mellers, B. a, Schwartz, a., Ho, K., \& Ritov, I. (1997). Decision
Affect Theory: Emotional Reactions to the Outcomes of Risky Options.
\emph{Psychological Science}, \emph{8}(6), 423--429.
\url{http://doi.org/10.1111/j.1467-9280.1997.tb00455.x}

\hypertarget{ref-Rescorla1972}{}
Rescorla, R. A., \& Wagner, A. R. (1972). A theory of Pavlovian
conditioning: Variations in the effectiveness of reinforcement and
nonreinforcement. In \emph{Classical conditioning ii current research
and theory} (Vol. 21, pp. 64--99).
\url{http://doi.org/10.1101/gr.110528.110}

\hypertarget{ref-Shannon1948}{}
Shannon, C. E. (1948). A Mathematical Theory of Communication.
\emph{Bell System Technical Journal}, \emph{27}(3), 379--423.
\url{http://doi.org/10.1002/j.1538-7305.1948.tb01338.x}

\hypertarget{ref-Shepperd2002}{}
Shepperd, J. a, \& Mcnulty, J. K. (2002). The affective consequences of
expected and unexpected outcomes. \emph{Psychological Science},
\emph{13}(1), 85--88. \url{http://doi.org/10.1111/1467-9280.00416}

\hypertarget{ref-Trope2010}{}
Trope, Y., \& Liberman, N. (2010). Construal-level theory of
psychological distance. \emph{Psychological Review}, \emph{117}(2),
440--63. \url{http://doi.org/10.1037/a0018963}

\hypertarget{ref-Tversky1992}{}
Tversky, A., \& Kahneman, D. (1992). Advances in prospect theory:
Cumulative representation of uncertainty. \emph{Journal of Risk and
Uncertainty}, \emph{5}, 297--323.


\end{document}
